{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def parse_txt(filename, oriented=True):\n",
    "    \"\"\"\n",
    "    Parse data from txt file into dict python type.\n",
    "    JSON serializable.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    with open(filename) as file:\n",
    "        \n",
    "        line = file.readline()\n",
    "        while line:\n",
    "            \n",
    "            # skip comments\n",
    "            if line[0] == '#':\n",
    "                line = file.readline()\n",
    "                continue\n",
    "            \n",
    "            parent, child = line.split()\n",
    "            \n",
    "            parent = int(parent)\n",
    "            child = int(child)\n",
    "            \n",
    "            # rows in data file can be duplicated\n",
    "            if parent in data:\n",
    "                if child not in data[parent]['linked']:\n",
    "                    data[parent]['linked'].append(child)\n",
    "                    data[parent]['degree'] += 1\n",
    "            else:\n",
    "                data[parent] = { \n",
    "                    'linked': [child],\n",
    "                    'degree': 1,\n",
    "                }\n",
    "                \n",
    "            if oriented:\n",
    "                if child not in data:\n",
    "                    data[child] = { \n",
    "                    'linked': [],\n",
    "                    'degree': 0,\n",
    "                }\n",
    "                \n",
    "            else:\n",
    "                if child in data:\n",
    "                    if parent not in data[child]['linked']:\n",
    "                        data[child]['linked'].append(parent)\n",
    "                        data[child]['degree'] += 1\n",
    "\n",
    "                else:    \n",
    "                    data[child] = {\n",
    "                        'linked': [parent],\n",
    "                        'degree': 1,\n",
    "                    }\n",
    "\n",
    "            line = file.readline()\n",
    "\n",
    "    return data\n",
    "\n",
    "def parse_csv(filename, oriented=True):\n",
    "    data = {}\n",
    "    \n",
    "    with open(filename) as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "            \n",
    "            parent = int(row[0])\n",
    "            child = int(row[1])\n",
    "            \n",
    "            if parent in data:\n",
    "                if child not in data[parent]['linked']:\n",
    "                    data[parent]['linked'].append(child)\n",
    "                    data[parent]['degree'] += 1\n",
    "            else:\n",
    "                data[parent] = { \n",
    "                    'linked': [child],\n",
    "                    'distances': {},\n",
    "                    'degree': 1,\n",
    "                    'centrality': 0,\n",
    "                    'marked': False,\n",
    "                    'active': True\n",
    "                }\n",
    "                \n",
    "            if oriented:\n",
    "                if child not in data:\n",
    "                    data[child] = { \n",
    "                    'linked': [],\n",
    "                    'distances': {},\n",
    "                    'degree': 1,\n",
    "                    'centrality': 0,\n",
    "                    'marked': False,\n",
    "                    'active': True\n",
    "                }\n",
    "                \n",
    "            else:\n",
    "                if child in data:\n",
    "                    if parent not in data[child]['linked']:\n",
    "                        data[child]['linked'].append(parent)\n",
    "                        data[child]['degree'] += 1\n",
    "\n",
    "                else:    \n",
    "                    data[child] = {\n",
    "                        'linked': [parent],\n",
    "                        'distances': {},\n",
    "                        'degree': 1,\n",
    "                        'centrality': 0,\n",
    "                        'marked': False,\n",
    "                        'active': True\n",
    "                    }\n",
    "                    \n",
    "    return data\n",
    "\n",
    "def parse(filename, oriented=True):\n",
    "    if filename.split('.')[-1] == 'txt':\n",
    "        return parse_txt(filename, oriented)\n",
    "    elif filename.split('.')[-1] == 'csv':\n",
    "        return parse_csv(filename, oriented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = '../datasets/vk.csv'\n",
    "#FILENAME = 'test.txt'\n",
    "ORIENTED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parse(FILENAME, ORIENTED)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vertices in ../datasets/vk.csv: 3215720\n",
      "Number of edges in ../datasets/vk.csv: 19023803\n",
      "Number of edges in complete graph: 5170425951340.0\n",
      "Density: 3.6793492797377113e-06\n"
     ]
    }
   ],
   "source": [
    "def count_vertices(graph):\n",
    "    return len(graph)\n",
    "\n",
    "def count_edges(graph,oriented = False):\n",
    "    edges = 0\n",
    "    for item in graph.values():\n",
    "        edges += item['degree']\n",
    "    if oriented:\n",
    "        return edges\n",
    "    return edges / 2\n",
    "\n",
    "vertices = count_vertices(data)\n",
    "edges = count_edges(data,ORIENTED)\n",
    "complete_graph_edges = vertices * (vertices - 1) / 2\n",
    "\n",
    "print(f'Number of vertices in {FILENAME}: {vertices}')\n",
    "print(f'Number of edges in {FILENAME}: {edges}')\n",
    "print(f'Number of edges in complete graph: {complete_graph_edges}')\n",
    "print(f'Density: {edges / complete_graph_edges}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-344b845c6a63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mweak_connectivity_components\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_weak_connectivity_component\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_weak_connectivity_components\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_unoriented\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mmax_weak_connectivity_component_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_weak_connectivity_component\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweak_connectivity_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-344b845c6a63>\u001b[0m in \u001b[0;36mget_weak_connectivity_components\u001b[1;34m(graph)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mcomponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0mnodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-344b845c6a63>\u001b[0m in \u001b[0;36mdfs\u001b[1;34m(graph, start, visited)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvisited\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"linked\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mvisited\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdfs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisited\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvisited\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "... last 1 frames repeated, from the frame below ...\n",
      "\u001b[1;32m<ipython-input-5-344b845c6a63>\u001b[0m in \u001b[0;36mdfs\u001b[1;34m(graph, start, visited)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvisited\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"linked\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mvisited\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdfs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisited\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvisited\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "def dfs(graph, start, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    visited.add(start)\n",
    "    for next in set(graph[start][\"linked\"]) - visited:\n",
    "        dfs(graph, next, visited)\n",
    "    return visited\n",
    "\n",
    "def get_weak_connectivity_components(graph):\n",
    "    weak_connectivity_components = []\n",
    "    max_component = []\n",
    "    nodes = []\n",
    "    for item in graph.keys():\n",
    "        if item not in nodes:\n",
    "            component = dfs(graph,item)\n",
    "            for key in component:\n",
    "                nodes.append(key)\n",
    "            if len(component) > len(max_component):\n",
    "                max_component = component\n",
    "            weak_connectivity_components.append(component)\n",
    "                \n",
    "    return (weak_connectivity_components, max_component)\n",
    "\n",
    "\n",
    "def make_unoriented(graph):\n",
    "    result = dict.fromkeys(graph.keys(),{})\n",
    "    for key in graph.keys():\n",
    "        result[key] = graph[key]\n",
    "    for key in result.keys():\n",
    "        for vertex in graph[key]['linked']:\n",
    "            if key not in result[vertex]['linked'] and key != vertex:\n",
    "                result[vertex]['linked'].append(key)\n",
    "                result[vertex]['degree'] += 1\n",
    "    return result\n",
    "    \n",
    "    \n",
    "[weak_connectivity_components,max_weak_connectivity_component] = get_weak_connectivity_components(make_unoriented(data))\n",
    "max_weak_connectivity_component_size = len(max_weak_connectivity_component)\n",
    "print(weak_connectivity_components)\n",
    "print(max_weak_connectivity_component_size)\n",
    "print(f'Number of weak connectivity components in {FILENAME}: {len(weak_connectivity_components)}')\n",
    "print(f'Proportion of vertices in max weak connectivity component: {max_weak_connectivity_component_size/vertices}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class Graph:\n",
    "   \n",
    "    def __init__(self,vertices,FILENAME=None):\n",
    "        self.V = vertices\n",
    "        self.graph = defaultdict(list) \n",
    "        if FILENAME:\n",
    "            self.parse(FILENAME)\n",
    "        \n",
    "    def parse(self,FILENAME):\n",
    "        with open(FILENAME) as file:\n",
    "            file.readline()\n",
    "            line = file.readline()\n",
    "            while line:\n",
    "\n",
    "                if line[0] == '#':\n",
    "                    line = file.readline()\n",
    "                    continue\n",
    "                \n",
    "                parent, child = line.split(',')[0:2]\n",
    "                parent = int(parent)\n",
    "                child = int(child)\n",
    "\n",
    "                self.addEdge(parent,child)\n",
    "\n",
    "                if parent in self.graph.keys():\n",
    "                    if child not in self.graph[parent]:\n",
    "                        self.graph[parent].append(child)\n",
    "                else:\n",
    "                    self.graph[parent] = [child]    \n",
    "\n",
    "                if child not in self.graph.keys():\n",
    "                    self.graph[child] = []\n",
    "\n",
    "                line = file.readline()\n",
    "    \n",
    "    def addEdge(self,u,v):\n",
    "        self.graph[u].append(v)\n",
    "   \n",
    "    def DFSUtil(self,v,visited,sublist):\n",
    "        visited[v] = True\n",
    "        sublist.append(v)\n",
    "        for i in self.graph[v]:\n",
    "            if visited[i] == False:\n",
    "                self.DFSUtil(i,visited,sublist)\n",
    "        return sublist\n",
    "  \n",
    "    def fillOrder(self,v,visited, stack):\n",
    "        visited[v] = True\n",
    "        for i in self.graph[v]:\n",
    "            if visited[i] == False:\n",
    "                self.fillOrder(i, visited, stack)\n",
    "        stack = stack.append(v)\n",
    "      \n",
    "    def getTranspose(self):\n",
    "        g = Graph(self.V)\n",
    "        \n",
    "        for i in self.graph:\n",
    "            for j in self.graph[i]:\n",
    "                g.addEdge(j,i)\n",
    "        return g\n",
    "  \n",
    "    def printSCCs(self):\n",
    "        result = []\n",
    "        stack = []\n",
    "        visited = dict.fromkeys(self.graph.keys(),False)\n",
    "        for i in visited.keys():\n",
    "            if visited[i] == False:\n",
    "                self.fillOrder(i, visited, stack)\n",
    "                \n",
    "        gr = self.getTranspose()\n",
    "        visited = dict.fromkeys(self.graph.keys(),False)\n",
    "  \n",
    "        while stack:\n",
    "             i = stack.pop()\n",
    "             if visited[i] == False:\n",
    "                result.append(gr.DFSUtil(i, visited,[]))\n",
    "        return result\n",
    "                \n",
    "\n",
    "graph = Graph(vertices,FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_strong_connectivity_component_size(components):\n",
    "    maximum = 0\n",
    "    for item in components:\n",
    "        if len(item) > maximum:\n",
    "            maximum = len(item)\n",
    "    return maximum\n",
    "\n",
    "if ORIENTED:\n",
    "    strong_connectivity_components = graph.printSCCs()\n",
    "    max_strong_connectivity_component_size = get_max_strong_connectivity_component_size(strong_connectivity_components)\n",
    "    print(f'Number of strong connectivity components in {FILENAME}: {len(strong_connectivity_components)}')\n",
    "    print(f'Proportion of vertices in max strong connectivity component: {max_strong_connectivity_component_size/vertices}')\n",
    "    print(f'Max strong connectivity component size: {max_strong_connectivity_component_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_component(component,data):\n",
    "    result = {}\n",
    "    for node in component:\n",
    "        result[node] = data[node]\n",
    "    for key,values in result.items():\n",
    "        for value in values['linked']:\n",
    "            if value not in component:\n",
    "                result[key]['linked'] = [x for x in result[key] if x != value]\n",
    "    return result\n",
    "        \n",
    "filled_component = fill_component(max_weak_connectivity_component,make_unoriented(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "import random\n",
    "    \n",
    "def minEdgeBFS(graph, u, v):\n",
    "    visited = dict.fromkeys(graph.keys(),False)\n",
    "    distance = dict.fromkeys(graph.keys(),0)\n",
    " \n",
    "    # queue to do BFS.\n",
    "    Q = queue.Queue()\n",
    "    Q.put(u)\n",
    "    visited[u] = True\n",
    "    while (not Q.empty()):\n",
    "        x = Q.get()\n",
    "        for i in graph[x]['linked']:\n",
    "            if visited[i]:\n",
    "                continue\n",
    " \n",
    "            distance[i] = distance[x] + 1\n",
    "            Q.put(i)\n",
    "            visited[i] = True\n",
    "    return distance[v]\n",
    " \n",
    "def distances(graph, number_of_verticies):\n",
    "    keys = [x for x in graph.keys()]\n",
    "    random.shuffle(keys)\n",
    "    random_keys = keys[0:number_of_verticies]\n",
    "    distances = {}\n",
    "    for i in random_keys:\n",
    "        distances[i] = {}\n",
    "        for j in random_keys:\n",
    "            if i != j:\n",
    "                distances[i][j] = 0\n",
    "                \n",
    "    for i in random_keys:\n",
    "        for j in random_keys:\n",
    "            if i != j:\n",
    "                distances[i][j] = minEdgeBFS(graph,i,j)\n",
    "    return distances\n",
    "\n",
    "distances = distances(filled_component,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_diameter(distances):\n",
    "    diameter = 0\n",
    "    for key, values in distances.items():\n",
    "        for node, distance in values.items():\n",
    "            if distance > diameter:\n",
    "                diameter = distance\n",
    "    return diameter\n",
    "\n",
    "def get_radius(distances):\n",
    "    radius = 1000000000000000\n",
    "    for key, values in distances.items():\n",
    "        e = 0\n",
    "        for node, distance in values.items():\n",
    "            if distance > e:\n",
    "                e = distance\n",
    "        if radius > e:\n",
    "            radius = e\n",
    "    return radius\n",
    "\n",
    "def get_r_percentile(distances,r):\n",
    "    d = []\n",
    "    for key, values in distances.items():\n",
    "        for node, distance in values.items():\n",
    "            d.append(distance)\n",
    "    d.sort()\n",
    "    return d[math.ceil(len(d)*r/100)]\n",
    "\n",
    "print(f\"diameter: {get_diameter(distances)}\")\n",
    "print(f\"raidus: {get_radius(distances)}\")\n",
    "print(f\"90 percentile: {get_r_percentile(distances,90)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\mytht\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mytht\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mytht\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mytht\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\mytht\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mytht\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mytht\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (9.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mytht\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mytht\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.22.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mytht\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\mytht\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#!pip install seaborn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "\n",
    "def get_degrees(graph):\n",
    "    min_degree = 100000000000000\n",
    "    max_degree = 0\n",
    "    avg_degree = 0\n",
    "    for vertex in graph.values():\n",
    "        if vertex['degree'] > max_degree:\n",
    "            max_degree = vertex['degree']\n",
    "        if vertex['degree'] < min_degree:\n",
    "            min_degree = vertex['degree']\n",
    "        avg_degree += vertex['degree']\n",
    "    return (min_degree,max_degree,avg_degree / len(graph.keys()))\n",
    "\n",
    "[min_degree,max_degree,avg_degree] = get_degrees(data)\n",
    "print(f'Minimum degree: {min_degree}')\n",
    "print(f'Maximum degree: {max_degree}')\n",
    "print(f'Average degree: {avg_degree}')\n",
    "\n",
    "def get_distribution(graph,degrees):\n",
    "    \n",
    "    degree_sum = 0\n",
    "    for value in graph.values():\n",
    "        degrees[value['degree']] += 1\n",
    "        degree_sum += value['degree']\n",
    "    for key in degrees.keys():\n",
    "        degrees[key] /= degree_sum\n",
    "    return degrees\n",
    "    \n",
    "def get_log_log(distribution):\n",
    "    res = {}\n",
    "    for key,value in distribution.items():\n",
    "        res[f'{math.log10(key+1)}'] = math.log10(value+1)\n",
    "    return res\n",
    "    \n",
    "distribution = get_distribution(data,dict.fromkeys(list(range(min_degree,max_degree+1)),0))\n",
    "log_distribution = get_log_log(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.histplot(data=list(distribution.values()),bins=30)\n",
    "plt.bar(distribution.keys(), distribution.values())\n",
    "  \n",
    "# naming the x axis\n",
    "plt.xlabel('Степень вершины')\n",
    "# naming the y axis\n",
    "plt.ylabel('Вероятность')\n",
    "# giving a title to my graph\n",
    "plt.title('Функция вероятности')\n",
    "  \n",
    "# function to show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.histplot(distribution,log_scale=True)\n",
    "plt.bar(distribution.keys(), distribution.values())\n",
    "  \n",
    "# naming the x axis\n",
    "plt.xlabel('Степень вершины')\n",
    "# naming the y axis\n",
    "plt.ylabel('Вероятность')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')  \n",
    "# giving a title to my graph\n",
    "plt.title('Функция вероятности в log-log шкале')\n",
    "  \n",
    "# function to show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
